{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/fernandoleonfranco/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/fernandoleonfranco/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/fernandoleonfranco/Documents/GitHub/Semestre_III/DataIntelligence/exist2021\n"
     ]
    }
   ],
   "source": [
    "os.chdir(r'/Users/fernandoleonfranco/Documents/GitHub/Semestre_III/DataIntelligence/exist2021')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño training: (6977, 7)\n",
      "Tamaño test: (4368, 7)\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos\n",
    "df_train = pd.read_csv(\"train.tsv\", sep='\\t')\n",
    "df_test = pd.read_csv(\"test.tsv\", sep='\\t')\n",
    "\n",
    "print('Tamaño training:', df_train.shape)\n",
    "print('Tamaño test:', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño training (solo inglés): (3436, 7)\n",
      "Tamaño test (solo inglés): (2208, 7)\n"
     ]
    }
   ],
   "source": [
    "# Filtrar por idioma inglés\n",
    "df_train = df_train[df_train['language'] == 'en']\n",
    "df_test = df_test[df_test['language'] == 'en']\n",
    "print('Tamaño training (solo inglés):', df_train.shape)\n",
    "print('Tamaño test (solo inglés):', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros registros del training:\n",
      "  language                                               text       label\n",
      "0       en  She calls herself \"anti-feminazi\" how about sh...      sexist\n",
      "1       en  Now, back to these women, the brave and the be...  non-sexist\n",
      "2       en  @CurvyBandida @Xalynne_B Wow, your skirt is ve...      sexist\n",
      "3       en  @AurelieGuiboud Incredible!  Beautiful!But I l...  non-sexist\n",
      "4       en  i find it extremely hard to believe that kelly...  non-sexist\n"
     ]
    }
   ],
   "source": [
    "# Preparar las columnas necesarias\n",
    "df_train = df_train.drop(['test_case', 'id', 'source', 'task2'], axis=1)\n",
    "df_test = df_test.drop(['test_case', 'id', 'source', 'task2'], axis=1)\n",
    "df_train = df_train.rename(columns={'task1': 'label'})\n",
    "df_test = df_test.rename(columns={'task1': 'label'})\n",
    "print('Primeros registros del training:')\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = stopwords.words(\"english\")\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()  # Minúsculas\n",
    "    from nltk.tokenize.punkt import PunktSentenceTokenizer\n",
    "    punkt_tokenizer = PunktSentenceTokenizer()  # Instanciar el tokenizador\n",
    "    \n",
    "    tokens = punkt_tokenizer.tokenize(text)  # Tokenizar\n",
    "    tokens = [word for word in tokens if word not in stopwords_en]  # Eliminar stopwords\n",
    "    tokens = [PorterStemmer().stem(word) for word in tokens]  # Stemming\n",
    "    min_length = 3\n",
    "    p = re.compile('^[a-zA-Z]+$')\n",
    "    filtered_tokens = [token for token in tokens if len(token) >= min_length and p.match(token)]\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semestre_tres",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
